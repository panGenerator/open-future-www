<!doctype html><html lang=en><meta charset=utf-8>
<title>Open Future</title>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png>
<link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png>
<link rel=manifest href=/site.webmanifest>
<meta name=viewport content="width=device-width,initial-scale=1">
<link rel=stylesheet href=/css/style.min.css><body>
<main class="main main-page container-fluid container-xl">
<div class="row header">
<div class="col-12 col-md-5 offset-md-1 text-center mt-5 gx-0 gx-sm-5 pb-5">
<a href=/ class=bg-body><img src=/images/logo.svg class="logo img-fluid" alt=logo></a>
</div>
</div>
<div class="row content">
<article class="page col-12 gx-0 mb-2" id=ai_commons-open-licensing-in-the-age-of-ai>
<div class="page-details px-5 text-small">
<h1>AI_Commons: Open licensing in the age of AI</h1>
<div class=w-100></div>
<div class=date>April 29, 2021 </div>
<div class="pt-3 pb-1"><p><em>Francesco Vogelezang, Alek Tarkowski</em></p>
<p>Machine training with openly licensed photographs of faces is a controversial use case of Creative Commons licensed content, identified several years ago. Since the case received <a href=https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html>media attention</a> in 2019, it has been often raised as an example of inherent conflict between openness and privacy protection as conflicting values.</p>
<p>In the background, there are growing concerns about the ethics of artificial intelligence and machine learning technologies, especially in relation to biometric data. Emblematically, <a href=https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1278>a 2018 academic publication by Wiley</a>, concerning algorithmic training to distinguish faces of Uyghur people from those of Korean and Tibetan ethnicity, sparked a great deal of controversy about the ethics of academic research in image training recognition. Likewise, <a href=https://ieeexplore.ieee.org/document/7780624>the 2018 revelations involving a group of scientists from Stanford University</a>, that approximately collected around 12,000 images from a webcam in a San Francisco café to train biometric categorization algorithms, signal the inherent <strong>struggle of user's consent to data processing with facial recognition training</strong>.</p>
<p>We are launching the AI_Commons project to find a solution to this issue. By studying this case, we hope to define better how governance of shared resources can balance open sharing with protection of personal data and privacy. We also see this as a case that concerns irrevocability of CC licenses and their unintended uses, and thus the challenge of making the CC licensing stack future-proof.</p>
<p>Finally, this is a case that explores the limit of the traditional approach to sharing, the Open Access Commons. And asks whether for some types of data we need a stronger, more managed commons and data governance. As this is also a case that deals with imbalances of power on the web – a <a href=http://paradox.openfuture.eu/>Paradox of Open</a> that we have identified.</p>
<h3 id=ai-is-a-challenge-for-open-licensing>AI is a challenge for open licensing</h3>
<p>These two episodes highlight the <strong>need for greater legal clarity on machine training with openly licensed material</strong>.
On the one hand, this is especially urgent in light of the ever growing <strong>need for facial recognition algorithms to be trained and tested on large image datasets</strong>. These are increasingly accessed from the Internet, where permissive licenses, such as from <a href=https://flickr.com/>Flickr.com</a>, allow the training of facial recognition algorithms with users' images.</p>
<p>On the other hand, the <strong>existing legislation seems not to provide sufficient guidance on the issue</strong>. Even in the European Union (EU), the world champion of privacy and data protection, the General Data Protection Regulation, despite not granting an obvious legal basis for researchers, lacks <a href=https://research.tilburguniversity.edu/en/publications/data-protection-and-privacy-the-internet-of-bodies>adequate clarity</a> as this issue has not been tested in courts yet.</p>
<p>However, this situation might soon change: the newly released <a href=https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-european-approach-artificial-intelligence>EU Proposal for a Regulation a European Approach for Artificial Intelligence (AI)</a> – the AI Act – sets the scene for greater legal certainty.
Specifically, <strong>Title IV of the Regulation</strong> stipulates important transparency obligations for certain AI systems that interact with natural persons, or that generate content based on the processing of their personal data. In particular, art. 52(2) is crucial here as it lays down notification obligations for users when they are exposed to emotion recognition or biometric categorisation systems, other than those available for the public to report a criminal offence.</p>
<p>Considering the potential destabilizing effects of human impersonation and deception based on users' data processing, the measure definitely sets the ground for greater users' awareness in the context of AI deployment. However, despite its ambitious character, the AI Act does not directly tackle the <strong>ethical controversies surrounding the use of permissive copyright licenses for AI facial recognition training</strong>. The latter still remains a crucial element of discussion that policymakers have so far failed to address, though these technologies continue to proliferate across more fields than mere academic research, such as for defense, military and law enforcement purposes. <strong>This is why we decided to launch AI_Commons!</strong></p>
<h3 id=ai_commons--designing-policies-for-machine-learning-with-open-datasets>AI_Commons – designing policies for machine learning with open datasets</h3>
<p>AI_Commons is a new <strong>research and policy design process</strong>, launched in collaboration with <a href=https://exposing.ai/>Exposing.ai</a>, where we explore more in depth the interconnection of permissive <a href=https://creativecommons.org/>Creative Commons (CC)</a> licenses with facial recognition training.
We have approached the Exposing.ai team after learning about their work on image training datasets – the Financial Times extensively talks about them <a href=https://www.ft.com/content/cf19b956-60a2-11e9-b285-3acd5d43599e>here</a>.</p>
<p>Specifically, Exposing.ai is an initiative created by the Berlin-based artist <a href=https://ahprojects.com/>Adam Harvey</a>, and technologist and programmers <a href=https://asdf.us/tools/>Jules LaPlace</a>, and is based on the earlier <a href=https://www.nytimes.com/2021/01/31/technology/facial-recognition-photo-tool.html>MegaPixels</a> project (2017-2020). This project is based on years and years of research about <strong>image training datasets used for facial recognition and related biometric analysis technologies</strong>. After having collected and analyzed hundreds of datasets, Adam and Jules detected a common pattern: <strong>millions of images were being downloaded from Flickr.com where permissive licenses allowed the processing of users' biometric data for facial recognition training</strong>.</p>
<p>All of this happened <strong>without users being fully aware</strong> that their images were being treated for such purpose. In other words, if you were a Flickr user and uploaded images containing faces or other biometric information between 2004 and 2020, your photos are highly likely to have been used to train, test, or enhance artificial intelligence surveillance technologies – on Exposing.ai, you can check whether your photos were used. Their work even led Microsoft to withdraw a <a href=https://www.ft.com/content/7d3e0d6a-87a0-11e9-a028-86cea8523dc2>database of 10m faces</a>, which has been used to train facial recognition systems around the world, including by military researchers and Chinese firms, such as SenseTime and Megvii.</p>
<p>As previously mentioned, <strong>considering the current policy vacuum, this issue deserves further attention by open movement advocates</strong>. A thorough assessment around the intersection of CC licenses with AI training is necessary to better consider the ethical implications of image recognition applications with openly licensed material. The fact that many users were simply unaware of their data processing taking place to train facial recognition technologies requires a deep reflection on the suitability of CC licenses with facial recognition algorithms.</p>
<p>A recent <a href=https://www.nature.com/articles/d41586-020-03187-3#ref-CR1>survey</a> published by Nature highlights how AI researchers working with facial recognition are currently divided on its ethical implications. Creative Commons previously tried to address the problem with an <a href=https://creativecommons.org/2019/03/13/statement-on-shared-images-in-facial-recognition-ai/>official statement</a> by shifting responsibility to other legal or ethical organizations. Yet, the problem still remains open and requires urgent action.
As AI, and especially facial recognition technologies, continue to proliferate, <strong>a new set of ethical standards concerning the use of publicly available images for AI training is becoming more and more urgent.</strong>
It is time to take action!</p>
<h3 id=next-steps>Next Steps</h3>
<p>AI_Commons aims to facilitate a better understanding of these issues by providing <strong>concrete policy solutions</strong>. This joint research and policy design process will <strong>investigate the use of open content for AI training</strong>. Broader context for this work is defined in our <a href=https://paradox.openfuture.eu/>Paradox of Open</a> essay.</p>
<p>Specifically, we are trying to understand <strong>how far open licenses are regarded as a signifier that licensed photos can be used to train (facial recognition) algorithms and how such uses relate to the intentions and expectations of licensors</strong>.
We will present our findings in an inception report, planned for later this year. We are also conducting a study to understand better the attitudes of people openly sharing their photographs to different ways these are reused, in particular for AI training. Afterwards, we will invite experts and activists from the broad open movement, and those with interest in regulating machine learning, to join us in a policy design process. Together, we want to identify whether there is a <strong>need for change within the open licensing ecosystem</strong>, which might consist in <strong>new tailormade licenses</strong>, additional <strong>guidance</strong> or specific <strong>regulatory interventions</strong>.
AI_Commons will finish with concrete recommendations and a public report.</p>
<p>To stay updated on the next developments concerning AI_Commons and similar policy initiatives, subscribe to our <a href="https://openfuture.us1.list-manage.com/subscribe/post?u=d7c6d2a743011f3253613888f&id=ca8ac23ac4">monthly newsletter</a>. And if you are interested in collaborating with us in the policy design phase, please get in touch at <a href=mailto:hello@openfuture.eu>hello@openfuture.eu</a>.</p>
<h3 id=ai_commons-syllabus>AI_Commons syllabus</h3>
<p>These 2019 articles by the<a href=https://www.ft.com/content/cf19b956-60a2-11e9-b285-3acd5d43599e> Financial Times</a> and <a href=https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html>New York Times </a>provide a general overview of the ethical and normative issues affecting facial recognition research. They enlist a variety of cases where the training of AI with openly licensed content has raised important privacy considerations. In doing so, they also introduce the work performed by Adam Harvey and Jules la Place with <a href=https://exposing.ai>exposing.ai</a>. There, you can check whether your pictures have been included in datasets which were then used to train facial recognition algorithms.</p>
<ul>
<li><a href=https://www.ft.com/content/cf19b956-60a2-11e9-b285-3acd5d43599e>“Who’s using your face? The ugly truth about facial recognition” (Financial Times, 2019)</a></li>
<li><a href=https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html>“How photos of your kids are powering facial recognition algorithms” (New York Times, 2019)</a></li>
<li><a href=https://exposing.ai>Exposing.ai website</a></li>
</ul>
<p><strong>Ethical considerations</strong></p>
<p>Concerning the various ethical considerations within the AI community, this <a href=https://www.nature.com/articles/d41586-020-03187-3>Nature article</a> written by Richard Van Noorden (2020) explores core normative beliefs and questions at the core of the facial recognition research community. In doing so, it reports the results of a survey investigating ethical attitudes amongst 480 researchers who have published papers on facial recognition.</p>
<ul>
<li>“<a href=https://www.nature.com/articles/d41586-020-03187-3>The ethical questions that haunt facial-recognition research” (Van Noorden, 2020)</a></li>
</ul>
<p><strong>Use CC-licenses for Machine Learning training</strong></p>
<p>In this <a href="https://www.youtube.com/watch?v=4gyWc_WYOYo">YouTube video</a>, Brigitte Vezina (2021), CC Director of Policy, discusses whether the use of copyright material and Creative Commons-licensed content should be used as input to train Machine Learning systems. The answer is that “it depends…”</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=4gyWc_WYOYo">“Should open content be used to train artificial intelligence?” (Vezina, 2021)</a></li>
</ul>
<p>Also, Ryan Merkley (former CEO of Creative Commons), <a href=https://creativecommons.org/2019/03/13/statement-on-shared-images-in-facial-recognition-ai/>in this blogpost</a>, reports CC official position on the 2019 IBM-Flickr Case where openly licensed material was used to train facial recognition algorithms. Ryan discussed the issue from a use and fair use perspective.</p>
<ul>
<li><a href=https://creativecommons.org/2019/03/13/statement-on-shared-images-in-facial-recognition-ai/>“Use and Fair Use: Statement on shared images in facial recognition AI” (Merkley, 2019)</a></li>
</ul>
<p><strong>Data protection and copyright considerations</strong></p>
<p>Finally, coming to the various legal tensions at stake, Andres Guadamuz (2019), in this <a href=https://www.technollama.co.uk/using-creative-commons-images-to-train-artificial-intelligence>blogpost</a>, discusses the IBM case from a copyright perspective.</p>
<ul>
<li><a href=https://www.technollama.co.uk/using-creative-commons-images-to-train-artificial-intelligence>“Using Creative Commons images to train artificial intelligence” (Guadamuz, 2019)</a></li>
</ul>
<p>On this very point, <a href=https://www.create.ac.uk/blog/2021/07/14/ai-machine-learning-and-eu-copyright-law/>Margoni and Kretschmer</a> (2021) further analyze the EU copyright regime as they discuss the exceptions provided for Text and Data Mining (TDM) activities. Specifically, as they present the tension between Machine Learning and Copyright, they come to the conclusion that there should be no need for a TDM exception for the act of extracting informational value from protected works.</p>
<ul>
<li><a href=https://www.create.ac.uk/blog/2021/07/14/ai-machine-learning-and-eu-copyright-law/>“A deeper look into the EU Text and Data Mining Exceptions” (Margoni & Kretschmer, 2021)</a></li>
</ul>
<p><a href=https://www.law.kuleuven.be/citip/blog/free-to-re-use-the-case-of-facial-images-scrapped-from-the-internet-and-compiled-in-mega-research-datasets/>Catherine Jasserand</a> (2020), discusses this issue from a data protection perspective by explaining when and how the GDPR allows for the processing of biometric data made available in the form of openly licensed content. Further, this <a href=https://newtech.law/en/likenesses-in-computer-games-real-life-people/>blogpost</a> by newtech law discusses the issue of consent from a personality rights perspective.</p>
<ul>
<li><a href=https://www.law.kuleuven.be/citip/blog/free-to-re-use-the-case-of-facial-images-scrapped-from-the-internet-and-compiled-in-mega-research-datasets/>“Free to re-use? The case of facial images scrapped from the Internet and compiled in mega research datasets” (Jasserand, 2020)</a></li>
<li><a href=https://newtech.law/en/likenesses-in-computer-games-real-life-people/>“Likenesses in computer games: Real-life people” (Newtech law, 2021)</a></li>
</ul>
<p>Last but not least, this paper by <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3578819">Flynn et al.</a> (2020) calls for the international community to take action by implementing user rights for research in the field of Artificial Intelligence. Specifically, the World Intellectual Property Organization (WIPO) is identified as a key international forum to advance multi stakeholder debate on the issue.</p>
<ul>
<li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3578819">“Implementing User Rights for Research in the Field of Artificial Intelligence: A Call for International Action” (Flynn et al., 2020)</a></li>
</ul>
<p><em>(This text has been updated on 21 September 2021).</em></p>
</div>
</div>
</article>
</div><div class="footer row mt-5 justify-content-center">
<div class="social py-5 col-12 col-lg-6 align-self-center text-center">
<a href=https://twitter.com/openfutureEU class=me-3>
<img src=/images/twitter.svg alt=twitter>
</a>
<a href=https://www.linkedin.com/company/open-future-foundation/>
<img src=/images/linkedin.svg class=me-3 alt="linked in">
</a>
<a class=email href=mailto:hello@openfuture.eu>hello@openfuture.eu</a>
</div>
<div class="info col-12 col-lg-6 align-self-center py-3 d-flex">
<div class="text-center text-lg-start align-self-center mx-auto d-flex">
<div>All content is published in the <a href=https://creativecommons.org/publicdomain/zero/1.0/>Public Domain</a><br>
Read our <a href=https://openfuture.eu/files/201023statutes_en.pdf>statutes</a>.</div>
</div>
</div>
</div><script src=/js/logo.b01eb6b48697aa2904cafde6e2614dafac31c37f8e1f842cb358ad33cd7ecffb.js></script></main>
</body>
</html>