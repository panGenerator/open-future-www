---
title: "AI_Commons: Open licensing in the age of AI"
date: 2021-04-29
publishdate: 2021-04-29
---
Machine training with openly licensed material is an ethical question that has long divided open movement activists. Emblematically, [a 2018 academic publication by Wiley](https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1278), concerning algorithmic training to distinguish faces of Uyghur people from those of Korean and Tibetan ethnicity, sparked a great deal of controversy about the ethics of academic research in image training recognition. Likewise, [the 2015 revelations involving a group of scientists from Stanford University](https://ieeexplore.ieee.org/document/7780624), that approximately collected around 12,000 images from a webcam in a San Francisco café to train biometric categorization algorithms, signal the inherent struggle of user&#39;s consent to data processing with facial recognition training. We are launching the AI\_Commons project to find a solution to this issue – one of several key [paradoxes of open](http://paradox.openfuture.eu/) that we have identified.

### AI is a challenge for open licensing

These two episodes highlight the need for greater legal clarity on machine training with openly licensed material. On the one hand, this is especially urgent in light of the ever growing need for facial recognition algorithms to be trained and tested on large image datasets. These are increasingly accessed from the Internet, where permissive licenses, such as from [Flickr.com](https://flickr.com/), allow the training of facial recognition algorithms with users&#39; images. On the other hand, existing legislation seems not to provide sufficient guidance on the issue. Even in the European Union (EU), the world champion of privacy and data protection, the General Data Protection Regulation, despite not granting an obvious legal basis for researchers, lacks [adequate clarity](https://research.tilburguniversity.edu/en/publications/data-protection-and-privacy-the-internet-of-bodies) as this issue has not been tested in courts yet.

However, this situation might soon change: the newly released [EU Proposal for a Regulation a European Approach for Artificial Intelligence (AI)](https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-european-approach-artificial-intelligence) – the AI Act – sets the scene for greater legal certainty. Specifically, Title IV of the Regulation stipulates important transparency obligations for certain AI systems that interact with natural persons, or that generate content based on the processing of their personal data. In particular, art. 52(2) is crucial here as it lays down notification obligations for users when they are exposed to emotion recognition or biometric categorisation systems, other than those available for the public to report a criminal offence.

Considering the potential destabilizing effects of human impersonation and deception based on users&#39; data processing, the measure definitely sets the ground for greater users&#39; awareness in the context of AI deployment. However, despite its ambitious character, the AI Act does not directly tackle the ethical controversies surrounding the use of permissive copyright licenses for AI facial recognition training. The latter still remains a crucial element of discussion that policymakers have so far failed to address, though these technologies continue to proliferate across more fields than mere academic research, such as for defense, military and law enforcement purposes. This is why we decided to launch AI\_Commons!

### AI\_Commons – designing policies for machine learning with open datasets

AI\_Commons is a new research and policy design process, launched in collaboration with [Exposing.ai](https://exposing.ai/), where we explore more in depth the interconnection of permissive [Creative Commons (CC)](https://creativecommons.org/) licenses with facial recognition training. We have approached the Exposing.ai team after learning about their work on image training datasets – the Financial Times extensively talks about them [here](https://www.ft.com/content/cf19b956-60a2-11e9-b285-3acd5d43599e). Specifically, Exposing.ai is an initiative created by Berlin-based artist [Adam Harvey](https://ahprojects.com/), and technologist and programmers [Jules LaPlace](https://asdf.us/tools/), and is based on the earlier [MegaPixels](https://www.nytimes.com/2021/01/31/technology/facial-recognition-photo-tool.html) project (2017-2020). This project is based on years and years of research about image training datasets used for facial recognition and related biometric analysis technologies. After having collected and analyzed hundreds of datasets, Adam and Jules detected a common pattern: millions of images were being downloaded from Flickr.com where permissive licenses allowed the processing of users&#39; biometric data for facial recognition training. All of this happened without users being fully aware that their images were being treated for such purpose. In other words, if you were a Flickr user and uploaded images containing faces or other biometric information between 2004 and 2020, your photos are highly likely to have been used to train, test, or enhance artificial intelligence surveillance technologies – on Exposing.ai, you can check whether your photos were used. Their work even led Microsoft to withdraw a [database of 10m faces](https://www.ft.com/content/7d3e0d6a-87a0-11e9-a028-86cea8523dc2), which has been used to train facial recognition systems around the world, including by military researchers and Chinese firms, such as SenseTime and Megvii.

As previously mentioned, considering the current policy vacuum, this issue deserves further attention by open movement advocates. A thorough assessment around the intersection of CC licenses with AI training is necessary to better consider the ethical implications of image recognition applications with openly licensed material. The fact that many users were simply unaware of their data processing taking place to train facial recognition technologies requires a deep reflection on the suitability of CC licenses with facial recognition algorithms. A recent [survey](https://www.nature.com/articles/d41586-020-03187-3#ref-CR1) published by Nature highlights how AI researchers working with facial recognition are currently divided on its ethical implications. Creative Commons previously tried to address the problem with an [official statement](https://creativecommons.org/2019/03/13/statement-on-shared-images-in-facial-recognition-ai/) by shifting responsibility to other legal or ethical organizations. Yet, the problem still remains open and requires urgent action. As AI, and especially facial recognition technologies, continue to proliferate, a new set of ethical standards concerning the use of publicly available images for AI training is becoming more and more urgent. It is time to take action!

### Next Steps

AI\_Commons aims to facilitate a better understanding of these issues by providing concrete policy solutions. This joint research and policy design process will investigate the use of open content for AI training. Broader context for this work is defined in our [Paradox of Open](https://paradox.openfuture.eu/) essay. Specifically, we are trying to understand how far open licenses are regarded as a signifier that licensed photos can be used to train (facial recognition) algorithms and how such uses relate to the intentions and expectations of licensors. We will present our findings in an inception report, planned for June 2021. At this point, we will invite experts and activists from the broad open movement, and those with interest in regulating machine learning, to join us in a policy design process. Together, we want to identify whether there is a need for change within the open licensing ecosystem, which might consist in new tailormade licenses, additional guidance or specific regulatory interventions. AI\_Commons will finish with concrete recommendations and a public report, set for publication at the end of 2021.

To stay updated on the next developments concerning AI\_Commons and similar policy initiatives, subscribe to our [monthly newsletter](https://openfuture.us1.list-manage.com/subscribe/post?u=d7c6d2a743011f3253613888f&amp;id=ca8ac23ac4). And if you are interested in collaborating with us in the policy design phase, please get in touch at [hello@openfuture.eu](mailto:hello@openfuture.eu).
Rendered
AI_Commons: Open licensing in the age of AI
Machine training with openly licensed material is an ethical question that has long divided open movement activists. Emblematically, a 2018 academic publication by Wiley, concerning algorithmic training to distinguish faces of Uyghur people from those of Korean and Tibetan ethnicity, sparked a great deal of controversy about the ethics of academic research in image training recognition. Likewise, the 2015 revelations involving a group of scientists from Stanford University, that approximately collected around 12,000 images from a webcam in a San Francisco café to train biometric categorization algorithms, signal the inherent struggle of user's consent to data processing with facial recognition training. We are launching the AI_Commons project to find a solution to this issue – one of several key paradoxes of open that we have identified.

AI is a challenge for open licensing
These two episodes highlight the need for greater legal clarity on machine training with openly licensed material. On the one hand, this is especially urgent in light of the ever growing need for facial recognition algorithms to be trained and tested on large image datasets. These are increasingly accessed from the Internet, where permissive licenses, such as from Flickr.com, allow the training of facial recognition algorithms with users' images. On the other hand, existing legislation seems not to provide sufficient guidance on the issue. Even in the European Union (EU), the world champion of privacy and data protection, the General Data Protection Regulation, despite not granting an obvious legal basis for researchers, lacks adequate clarity as this issue has not been tested in courts yet.

However, this situation might soon change: the newly released EU Proposal for a Regulation a European Approach for Artificial Intelligence (AI) – the AI Act – sets the scene for greater legal certainty. Specifically, Title IV of the Regulation stipulates important transparency obligations for certain AI systems that interact with natural persons, or that generate content based on the processing of their personal data. In particular, art. 52(2) is crucial here as it lays down notification obligations for users when they are exposed to emotion recognition or biometric categorisation systems, other than those available for the public to report a criminal offence.

Considering the potential destabilizing effects of human impersonation and deception based on users' data processing, the measure definitely sets the ground for greater users' awareness in the context of AI deployment. However, despite its ambitious character, the AI Act does not directly tackle the ethical controversies surrounding the use of permissive copyright licenses for AI facial recognition training. The latter still remains a crucial element of discussion that policymakers have so far failed to address, though these technologies continue to proliferate across more fields than mere academic research, such as for defense, military and law enforcement purposes. This is why we decided to launch AI_Commons!

AI_Commons – designing policies for machine learning with open datasets
AI_Commons is a new research and policy design process, launched in collaboration with Exposing.ai, where we explore more in depth the interconnection of permissive Creative Commons (CC) licenses with facial recognition training. We have approached the Exposing.ai team after learning about their work on image training datasets – the Financial Times extensively talks about them here. Specifically, Exposing.ai is an initiative created by Berlin-based artist Adam Harvey, and technologist and programmers Jules LaPlace, and is based on the earlier MegaPixels project (2017-2020). This project is based on years and years of research about image training datasets used for facial recognition and related biometric analysis technologies. After having collected and analyzed hundreds of datasets, Adam and Jules detected a common pattern: millions of images were being downloaded from Flickr.com where permissive licenses allowed the processing of users' biometric data for facial recognition training. All of this happened without users being fully aware that their images were being treated for such purpose. In other words, if you were a Flickr user and uploaded images containing faces or other biometric information between 2004 and 2020, your photos are highly likely to have been used to train, test, or enhance artificial intelligence surveillance technologies – on Exposing.ai, you can check whether your photos were used. Their work even led Microsoft to withdraw a database of 10m faces, which has been used to train facial recognition systems around the world, including by military researchers and Chinese firms, such as SenseTime and Megvii.

As previously mentioned, considering the current policy vacuum, this issue deserves further attention by open movement advocates. A thorough assessment around the intersection of CC licenses with AI training is necessary to better consider the ethical implications of image recognition applications with openly licensed material. The fact that many users were simply unaware of their data processing taking place to train facial recognition technologies requires a deep reflection on the suitability of CC licenses with facial recognition algorithms. A recent survey published by Nature highlights how AI researchers working with facial recognition are currently divided on its ethical implications. Creative Commons previously tried to address the problem with an official statement by shifting responsibility to other legal or ethical organizations. Yet, the problem still remains open and requires urgent action. As AI, and especially facial recognition technologies, continue to proliferate, a new set of ethical standards concerning the use of publicly available images for AI training is becoming more and more urgent. It is time to take action!

Next Steps
AI_Commons aims to facilitate a better understanding of these issues by providing concrete policy solutions. This joint research and policy design process will investigate the use of open content for AI training. Broader context for this work is defined in our Paradox of Open essay. Specifically, we are trying to understand how far open licenses are regarded as a signifier that licensed photos can be used to train (facial recognition) algorithms and how such uses relate to the intentions and expectations of licensors. We will present our findings in an inception report, planned for June 2021. At this point, we will invite experts and activists from the broad open movement, and those with interest in regulating machine learning, to join us in a policy design process. Together, we want to identify whether there is a need for change within the open licensing ecosystem, which might consist in new tailormade licenses, additional guidance or specific regulatory interventions. AI_Commons will finish with concrete recommendations and a public report, set for publication at the end of 2021.

To stay updated on the next developments concerning AI_Commons and similar policy initiatives, subscribe to our monthly newsletter. And if you are interested in collaborating with us in the policy design phase, please get in touch at hello@openfuture.eu.
